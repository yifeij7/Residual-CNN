{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gqhuAQBTLYpg"},"outputs":[],"source":["#Using codes from https://github.com/EemeliSaari/dmcnn-vd as reference\n","from  scipy import ndimage\n","import os\n","import scipy\n","import random\n","from google.colab.patches import cv2_imshow\n","from zipfile import ZipFile\n","import matplotlib.pyplot as plt\n","import cv2\n","from  scipy import ndimage\n","import numpy as np\n","import requests\n","import torch\n","import glob\n","import torch.utils.data\n","import imageio\n","from torchsummary import summary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVmF-PDBVdSv"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-902l4WKgyd"},"outputs":[],"source":["def demosaicing_checkboard_bili(img):\n","  kernel = np.array(\n","          [[0, 1, 0],\n","            [1, 4, 1],\n","            [0, 1, 0]]) / 4\n","  R = scipy.ndimage.convolve(img[:,:,2], kernel)\n","  B = scipy.ndimage.convolve(img[:,:,0], kernel)\n","  G = scipy.ndimage.convolve(img[:,:,1], kernel)\n","  checkboard = np.dstack((B,G,R))\n","  return checkboard\n","\n","def mosaicing_checkboard(img):\n","  x = np.ones((img.shape),dtype=int)\n","  x[1::2,::2,:] = 0\n","  x[::2,1::2,:] = 0\n","  mosaic = img * x\n","  return mosaic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LmejdcrH9w1"},"outputs":[],"source":["class ImagePatchDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, root, loader=None, sample_size=None,patch_size=(50, 50)):\n","        self.root = root\n","        self.transform = torch.from_numpy\n","        self.patch_size = patch_size\n","        self.loader = self._numpy_loader\n","\n","        self.sample_size = sample_size\n","        files = os.listdir(root)\n","\n","        self.files_ = list(map(lambda x: os.path.join(root, x), files))\n","        self.images_ = list(map(lambda x: np.array(self.loader(x)), self.files_))\n","        self.cfa_ = list(map(self._mosaic, self.images_))\n","        self.patches_ = self._compute_patches(self.images_)\n","        self.bilinears_ = list(map(self._bilin, self.cfa_))\n","\n","    def __getitem__(self, idx):\n","        patch, img_id = self.patches_[idx]\n","        x, y = patch\n","        b0, b1 = self.patch_size\n","        truth = self.images_[img_id][x - b0:x, y - b1:y, :]\n","        cfa = self.cfa_[img_id][x - b0:x, y - b1:y].reshape((3, 50, 50)) / 255\n","        truth = truth.reshape((3, 50, 50)) / 255\n","        bilin = self.bilinears_[img_id][x - b0:x, y- b1:y, :].reshape((3, 50, 50)) / 255\n","        return cfa, truth, bilin\n","    def __len__(self):\n","        return len(self.patches_)\n","    def _compute_patches(self, images):\n","        patches = []\n","        for idx, img in enumerate(images):\n","            image_patch = []\n","            M, N, Z = img.shape\n","            b0, b1 = self.patch_size\n","            for i in range(b0, M-b0, 5):\n","                for j in range(b1, N-b1, 5):\n","                    image_patch.append(([i, j], idx))\n","            image_patch = random.sample(image_patch, self.sample_size)\n","            patches += image_patch\n","        return patches\n","\n","    def _numpy_loader(self, path):\n","        return cv2.cvtColor(cv2.imread(path, 1), cv2.COLOR_BGR2RGB)\n","\n","    def _mosaic(self, img):\n","        cfa = np.zeros(img.shape, np.uint8)\n","        mosaic = mosaicing_checkboard(img)\n","        for i in range(3):\n","            cfa[:, :, i] = mosaic[:, :, i]\n","        return cfa\n","\n","    def _bilin(self, cfa):\n","        bilin = demosaicing_checkboard_bili(cfa)\n","        return bilin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ijtMVsu2eBZR"},"outputs":[],"source":["class Residaul_CNN(torch.nn.Module):\n","    def __init__(self, n_layers=20):\n","        super(Residaul_CNN, self).__init__()\n","        self.n_layers = n_layers\n","        self.layer0 = torch.nn.Sequential(\n","            torch.nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            torch.nn.BatchNorm2d(64),\n","            torch.nn.SELU()\n","        )\n","        for i in range(1, self.n_layers):\n","            setattr(self, f'layer{i}', self.conv_layer)\n","        self.residual = torch.nn.Sequential(\n","            torch.nn.Conv2d(64, 3, kernel_size=3, padding=1, bias=False),\n","            torch.nn.BatchNorm2d(3),\n","            torch.nn.SELU(inplace=True)\n","        )\n","        self.apply(self._msra_init)\n","\n","    def forward(self, x):\n","        out = getattr(self, 'layer0')(x)\n","        for i in range(1, self.n_layers):\n","            out = getattr(self, f'layer{i}')(out)\n","        out = self.residual(out)\n","        return out\n","\n","    def conv_layer(self):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            torch.nn.BatchNorm2d(64),\n","            torch.nn.SELU()\n","        )\n","\n","    def n_params(self):\n","        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","    def _msra_init(self, m):\n","        if isinstance(m, torch.nn.Conv2d):\n","            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","            m.weight.data.normal_(0, np.sqrt(2./n))\n","        elif isinstance(m, torch.nn.BatchNorm2d):\n","            torch.nn.init.constant_(m.weight, 1)\n","            torch.nn.init.constant_(m.bias, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rf73D_o3eCsc"},"outputs":[],"source":["model_vd = Residaul_CNN().cuda()\n","summary(model_vd, input_size=(3, 50, 50))\n","print(model_vd)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OsSd0G_KzOn6"},"outputs":[],"source":["dataset = ImagePatchDataset(root=\"/content/drive/My Drive/Colab Notebooks/pristine_images\", sample_size=100)\n","print(len(dataset))\n","data_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)"]},{"cell_type":"code","source":["import glob\n","import math\n","demo_PSNR_mean_list = []\n","demo_PSNR_training_mean_list = []\n","def PSNR(original, compressed):\n","    mse = np.mean((original - compressed) ** 2)\n","    if(mse == 0):\n","        return 100\n","    max_pixel = 255.0\n","    psnr = 20 * math.log10(max_pixel / math.sqrt(mse))\n","    return psnr\n","\n","def cal_average(num):\n","    sum_num = 0\n","    if(len(num)>0):\n","      for t in num:\n","          sum_num = sum_num + t\n","      avg = sum_num / len(num)\n","      return avg\n","\n","def testing_function(model_vd, images):\n","  bili_PSNR = []\n","  demo_PSNR = []\n","  bili_mse = []\n","  demo_mse = []\n","  bili_PSNR_mean = 0\n","  demo_PSNR_mean = 0\n","  for iii in range(len(images)):\n","    images[iii] = cv2.cvtColor(images[iii], cv2.COLOR_BGR2RGB)\n","    raw_image = images[iii]\n","    raw_image = raw_image[0:raw_image.shape[0],0:raw_image.shape[1],:]\n","    mosaic = mosaicing_checkboard(raw_image)\n","    bilin = demosaicing_checkboard_bili(mosaic).astype(np.int16)\n","    image_patches = []\n","    patches = []\n","    bilin_patches = []\n","    origin_pathces = []\n","    for i in range(50, mosaic.shape[0], 50):\n","        for j in range(50, mosaic.shape[1], 50):\n","            patch_mosaic = mosaic[i-50:i, j-50:j,:]\n","            patch = np.zeros((50, 50, 3), np.int16)\n","            for idx in range(3):\n","                patch[:, :, idx] = patch_mosaic[:,:,idx]\n","            patches.append((i, j))\n","            image_patches.append(patch)\n","            bilin_patches.append(bilin[i-50:i, j-50:j, :])\n","            origin_pathces.append(raw_image[i-50:i, j-50:j, :])\n","    tensor_patches = torch.from_numpy(np.stack(image_patches).reshape((len(image_patches), 3, 50, 50)) / 255.0).float().to(device)\n","    results = []\n","    with torch.no_grad():\n","        for i in range(0, tensor_patches.shape[0], 128):\n","            input_patch = tensor_patches[i:i+128, :, :, :]\n","            outputs = model_vd(input_patch) #+ input_patch\n","            results.append(outputs)\n","    results = torch.cat(results)\n","    demosaiced = np.zeros(raw_image.shape, np.int16)\n","    bili = np.zeros(raw_image.shape, np.int16)\n","    result = np.zeros(raw_image.shape, np.int16)\n","    for idx, patch in enumerate(patches):\n","        i, j = patch\n","        demosaic_patch = results[idx, :, :, :].reshape(50, 50, 3)\n","        demosaiced[i-50:i, j-50:j, :] = (np.array(demosaic_patch.tolist())*255 + bilin_patches[idx])\n","    result = np.zeros(raw_image.shape, np.float)\n","    import math\n","    for idx, patch in enumerate(patches):\n","        i, j = patch\n","        demosaic_patch = results[idx, :, :, :].reshape(50, 50, 3)\n","        demo = (np.array(demosaic_patch.tolist())*255)\n","        demosaiced[i-50:i, j-50:j, :] = demo + bilin_patches[idx]\n","    result[:,:,0] = demosaiced[:,:,0]\n","    result[:,:,1] = demosaiced[:,:,1]\n","    result[:,:,2] = demosaiced[:,:,2]\n","    result = result[0:raw_image.shape[0]-50,0:raw_image.shape[1]-50,:]\n","    ground_truth = raw_image[0:raw_image.shape[0]-50,0:raw_image.shape[1]-50,:]\n","    raw_image2 =PSNR(ground_truth.astype(np.int16),result.astype(np.int16))\n","    demo_PSNR.append(raw_image2)\n","  return cal_average(demo_PSNR)"],"metadata":{"id":"Ac0jVlPCpKfG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S974XmAWasyb"},"outputs":[],"source":["criterion = torch.nn.MSELoss()\n","optimizer_vd = torch.optim.Adam(model_vd.parameters(), lr=1e-5)\n","n_epochs = 200\n","device = torch.device('cuda:0')\n","total_step = len(data_loader)\n","loss_list = []\n","demo_best = 30\n","for epoch in range(start_epoch, n_epochs):\n","    epoch_loss = []\n","    for idx, (cfa, target, bilin) in enumerate(data_loader):\n","        cfa = cfa.float().to(device)\n","        target = target.float().to(device)\n","        bilin = bilin.float().to(device)\n","        target.cuda()\n","        outputs = model_vd(cfa)\n","\n","        #print(outputs.shape, target.shape)\n","        loss = criterion(outputs + bilin, target)\n","        epoch_loss.append(loss.item())\n","\n","        optimizer_vd.zero_grad()\n","        loss.backward()\n","        optimizer_vd.step()\n","\n","        if idx % 200 == 0:\n","            print(f'Epoch [{epoch}/{n_epochs}], Step [{idx}/{total_step}], Loss: {loss.item()}')\n","    epoch_stats = np.array(epoch_loss)\n","    psnr_epoch = 20 * math.log10(1.0 / math.sqrt(epoch_stats.mean()))\n","    print(f'\\nFinished Epoch {epoch}, Loss --- mean: {epoch_stats.mean()}, std {epoch_stats.std()}\\n')\n","    loss_list.append(epoch_stats.mean())\n","    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12,8))\n","    ax1.imshow(np.array(outputs[-1].tolist()).reshape((50, 50, 3)) + np.array(bilin[-1].tolist()).reshape((50, 50, 3)))\n","    ax2.imshow(np.array(cfa[-1].tolist()).reshape((50, 50, 3)), cmap='gray')\n","    ax3.imshow(np.array(target[-1].tolist()).reshape((50, 50, 3)))\n","    demo_PSNR_mean = testing_function(model_vd, KodakImages)\n","    print(\"Current mean PSNR\",demo_PSNR_mean)\n","    print(\"Current mean PSNR training\", psnr_epoch)\n","    if demo_PSNR_mean > demo_best:\n","      print(\"Better!\")\n","      demo_best = demo_PSNR_mean\n","      torch.save(model_vd.state_dict(), \"/content/drive/My Drive/Colab Notebooks/20layers_100sample_50size_checkboard_best.pt\")\n","    print(\"Best mean PSNR\",demo_best)\n","    demo_PSNR_mean_list.append(demo_PSNR_mean)\n","    demo_PSNR_training_mean_list.append(psnr_epoch)\n","    plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E5ixZUTi6x8A"},"outputs":[],"source":["import glob\n","from sklearn.metrics import mean_absolute_error\n","from skimage import data, img_as_float, io, color\n","from skimage.metrics import structural_similarity as ssim\n","from skimage.metrics import mean_squared_error\n","model_path = '/content/drive/My Drive/Colab Notebooks/20layers_100sample_50size_checkboard_best.pt'\n","device = torch.device('cuda:0')\n","model_vdd = Residaul_CNN().cuda()\n","model_vdd.load_state_dict(torch.load(model_path))\n","model_vd = model_vdd.eval()\n","#helper functions\n","def PSNR(original, compressed):\n","    psnr = [0,0,0]\n","    for i in range(3):\n","        original_mono = original[:,:,i]\n","        compressed_mono = compressed[:,:,i]\n","        mse = np.mean((original_mono.astype(float) - compressed_mono.astype(float)) ** 2)\n","        if(mse == 0):\n","            psnr[i]=100\n","        else:\n","            max_pixel = 255.0\n","            psnr[i] = 20 * math.log10(max_pixel / math.sqrt(mse))\n","    return psnr\n","\n","def MSE(original, compressed):\n","    MSE = [0,0,0]\n","    for i in range(3):\n","        original_mono = original[:,:,i]\n","        compressed_mono = compressed[:,:,i]\n","        mse= np.mean((original_mono.astype(float) - compressed_mono.astype(float)) ** 2)\n","        MSE[i] = mse/np.mean(original_mono)\n","    return MSE\n","\n","def SSIM(original, compressed,quant):\n","  ssim_const,tt = ssim(original, compressed, data_range=(compressed.max() - compressed.min())*1, channel_axis = -1, full=True)\n","  return 1-np.quantile(tt.ravel(), 1-quant)  #ssim_const\n","\n","\n","\n","def delta_E(original, compressed,quant):\n","  lab1 = color.rgb2lab(original)\n","  lab2 = color.rgb2lab(compressed)\n","  deltaE_s = color.deltaE_ciede2000(lab1, lab2, channel_axis=-1)\n","  return np.quantile(deltaE_s.ravel(),quant)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHO2d0m_H70m"},"outputs":[],"source":["import struct\n","bili_PSNR = []\n","demo_PSNR = []\n","bili_MSE = []\n","demo_MSE = []\n","SAE_demo = 0\n","MSE_demo = 0\n","SSIM_demo = 0\n","delataE_demo = 0\n","PSNR_demo = 0\n","SAE_bili = 0\n","MSE_bili = 0\n","SSIM_bili = 0\n","delataE_bili = 0\n","PSNR_bili = 0\n","bili_PSNR_RGB = []\n","demo_PSNR_RGB = []\n","demo_MSE_RGB = []\n","bili_MSE_RGB = []\n","demo_SSIM_RGB = []\n","bili_SSIM_RGB = []\n","demo_deltaE_RGB = []\n","bili_deltaE_RGB = []\n","images = [cv2.imread(file) for file in glob.glob(\"/content/drive/My Drive/Colab Notebooks/WED/*.bmp\")]\n","\n","\n","quant = 0.95\n","for iii in range(len(images)):\n","  images[iii] = cv2.cvtColor(images[iii], cv2.COLOR_BGR2RGB)\n","  raw_image = images[iii]\n","  raw_image2 = images[iii]\n","  raw_image = np.zeros((raw_image2.shape[0]+50,raw_image2.shape[1]+50,raw_image2.shape[2]))\n","  raw_image[:,:,0] = np.pad(raw_image2[:,:,0], [(0, 50), (0, 50)], mode='constant')\n","  raw_image[:,:,1] = np.pad(raw_image2[:,:,1], [(0, 50), (0, 50)], mode='constant')\n","  raw_image[:,:,2] = np.pad(raw_image2[:,:,2], [(0, 50), (0, 50)], mode='constant')\n","\n","  mosaic = mosaicing_checkboard(raw_image)\n","  bilin = demosaicing_checkboard_bili(mosaic)\n","  image_patches = []\n","  patches = []\n","  bilin_patches = []\n","  origin_pathces = []\n","\n","  for i in range(50, mosaic.shape[0], 50):\n","      for j in range(50, mosaic.shape[1], 50):\n","          patch_mosaic = mosaic[i-50:i, j-50:j,:]\n","          patch = np.zeros((50, 50, 3), np.int16)\n","          for idx in range(3):\n","              patch[:, :, idx] = patch_mosaic[:,:,idx]\n","          patches.append((i, j))\n","          image_patches.append(patch)\n","          bilin_patches.append(bilin[i-50:i, j-50:j, :])\n","          origin_pathces.append(raw_image[i-50:i, j-50:j, :])\n","  tensor_patches = torch.from_numpy(np.stack(image_patches).reshape((len(image_patches), 3, 50, 50)) / 255.0).float().to(device)\n","  results = []\n","  with torch.no_grad():\n","      feature_maps = []\n","      for i in range(0, tensor_patches.shape[0],128):\n","          input_patch = tensor_patches[i:i+128, :, :, :]\n","          outputs = model_vd(input_patch)\n","          hook.remove()\n","          results.append(outputs)\n","  results = torch.cat(results)\n","\n","  popo = results.cpu().detach().numpy()\n","\n","  demosaiced = np.zeros(raw_image.shape, np.int16)\n","  last_layer = np.zeros(raw_image.shape,float)\n","  origin = np.zeros(raw_image.shape, np.int16)\n","  bili = np.zeros(raw_image.shape, np.int16)\n","  result = np.zeros(raw_image.shape, np.int16)\n","\n","  for idx, patch in enumerate(patches):\n","      i, j = patch\n","      demosaic_patch = results[idx, :, :, :].reshape(50, 50, 3)\n","      demosaiced[i-50:i, j-50:j, :] = (np.array(demosaic_patch.tolist())*255 + bilin_patches[idx])\n","  bili = np.zeros(raw_image.shape, float)\n","  result = np.zeros(raw_image.shape, float)\n","  import math\n","  bili_PSNR_patch = []\n","  demo_PSNR_patch = []\n","\n","  for idx, patch in enumerate(patches):\n","      i, j = patch\n","      demosaic_patch = results[idx, :, :, :].reshape(50, 50, 3)\n","      demo = (np.array(demosaic_patch.tolist())*255)\n","      demosaiced[i-50:i, j-50:j, :] = demo + bilin_patches[idx]\n","      bili[i-50:i, j-50:j, :] = bilin_patches[idx]\n","      origin[i-50:i, j-50:j, :] = origin_pathces[idx]\n","      last_layer[i-50:i, j-50:j, :] = demo\n","\n","  result[:,:,0] = demosaiced[:,:,0]\n","  result[:,:,1] = demosaiced[:,:,1]\n","  result[:,:,2] = demosaiced[:,:,2]\n","  result = cv2.convertScaleAbs(result[0:raw_image.shape[0]-50,0:raw_image.shape[1]-50,:].astype(np.int16))#residual cnn output\n","  bili = cv2.convertScaleAbs(bilin[0:raw_image.shape[0]-50,0:raw_image.shape[1]-50,:].astype(np.int16))#bilinear output\n","  ground_truth = cv2.convertScaleAbs(raw_image[0:raw_image.shape[0]-50,0:raw_image.shape[1]-50,:].astype(np.int16))#groundthruth\n","\n","\n","  bili_PSNR_RGB.append(PSNR(ground_truth,bili))\n","  demo_PSNR_RGB.append(PSNR(ground_truth,result))\n","  bili_MSE_RGB.append(MSE(ground_truth,bili))\n","  demo_MSE_RGB.append(MSE(ground_truth,result))\n","  bili_SSIM_RGB.append(SSIM(ground_truth,bili,quant))\n","  demo_SSIM_RGB.append(SSIM(ground_truth,result,quant))\n","  bili_deltaE_RGB.append(delta_E(ground_truth,bili,quant))\n","  demo_deltaE_RGB.append(delta_E(ground_truth,result,quant))\n","\n","bili_PSNR_RGB_mean = np.mean(bili_PSNR_RGB, axis = 0)\n","demo_PSNR_RGB_mean = np.mean(demo_PSNR_RGB, axis = 0)\n","bili_MSE_RGB_mean = np.mean(bili_MSE_RGB, axis = 0)\n","demo_MSE_RGB_mean = np.mean(demo_MSE_RGB, axis = 0)\n","bili_SSIM_RGB_mean = np.mean(bili_SSIM_RGB, axis = 0)\n","demo_SSIM_RGB_mean = np.mean(demo_SSIM_RGB, axis = 0)\n","bili_deltaE_RGB_mean = np.mean(bili_deltaE_RGB, axis = 0)\n","demo_deltaE_RGB_mean = np.mean(demo_deltaE_RGB, axis = 0)\n","\n","bili_PSNR_RGB_std = np.std(bili_PSNR_RGB, axis = 0)\n","demo_PSNR_RGB_std = np.std(demo_PSNR_RGB, axis = 0)\n","bili_MSE_RGB_std = np.std(bili_MSE_RGB, axis = 0)\n","demo_MSE_RGB_std = np.std(demo_MSE_RGB, axis = 0)\n","bili_SSIM_RGB_std = np.std(bili_SSIM_RGB, axis = 0)\n","demo_SSIM_RGB_std = np.std(demo_SSIM_RGB, axis = 0)\n","bili_deltaE_RGB_std = np.std(bili_deltaE_RGB, axis = 0)\n","demo_deltaE_RGB_std = np.std(demo_deltaE_RGB, axis = 0)\n","\n","print(\"Demosaicing\")\n","print(\"bili_PSNR_RGB_mean:\",bili_PSNR_RGB_mean)\n","print(\"demo_PSNR_RGB_mean:\",demo_PSNR_RGB_mean)\n","print(\"bili_MSE_RGB_mean:\",bili_MSE_RGB_mean)\n","print(\"demo_MSE_RGB_mean:\",demo_MSE_RGB_mean)\n","print(\"bili_SSIM_RGB_mean:\",bili_SSIM_RGB_mean)\n","print(\"demo_SSIM_RGB_mean:\",demo_SSIM_RGB_mean)\n","print(\"bili_deltaE_RGB_mean:\",bili_deltaE_RGB_mean)\n","print(\"demo_deltaE_RGB_mean:\",demo_deltaE_RGB_mean)\n","\n","print(\"bili_PSNR_RGB_std:\",bili_PSNR_RGB_std)\n","print(\"demo_PSNR_RGB_std:\",demo_PSNR_RGB_std)\n","print(\"bili_MSE_RGB_std:\",bili_MSE_RGB_std)\n","print(\"demo_MSE_RGB_std:\",demo_MSE_RGB_std)\n","print(\"bili_SSIM_RGB_std:\",bili_SSIM_RGB_std)\n","print(\"demo_SSIM_RGB_std:\",demo_SSIM_RGB_std)\n","print(\"bili_deltaE_RGB_std:\",bili_deltaE_RGB_std)\n","print(\"demo_deltaE_RGB_std:\",demo_deltaE_RGB_std)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1n0VMOFcCehiHqYan-ET_OwHPdns-qjQ_","timestamp":1682544386133},{"file_id":"1Ye_bCT0MUsCvJIRp8tkxSBZUkU7Md4CJ","timestamp":1681791857247},{"file_id":"1qqHRLXHvXTRUJej_UZOc4i2qdA3-ke3X","timestamp":1681758466880},{"file_id":"1C1XaxIx_-uyN9ckzOY0cjz0CQ2Z-U0Ob","timestamp":1680710027640}],"private_outputs":true,"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}